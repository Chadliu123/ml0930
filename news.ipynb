{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1BIk9LoFNJ3HVCLNEkgubolA54YYqTcvF",
      "authorship_tag": "ABX9TyOMJxedwhGhLMr8q9lRLfMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/ml0930/blob/master/news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldoyAA7pw3tK"
      },
      "source": [
        "import zipfile\n",
        "path = \"drive/My Drive/news/chinese_news_trans.zip\"\n",
        "f = zipfile.ZipFile(path)\n",
        "f.extractall()\n",
        "path = \"drive/My Drive/news/chinese_news_test.zip\"\n",
        "f = zipfile.ZipFile(path)\n",
        "f.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBlr_kSOzHeQ"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "def read_data(base):\n",
        "    contents, targets = [], []\n",
        "    basedn = os.path.join(base, \"*\")\n",
        "    for dn in glob.glob(basedn):\n",
        "        upper = os.path.join(dn, \"*.TXT\")\n",
        "        lower = os.path.join(dn, \"*.txt\")\n",
        "        for fn in glob.glob(upper) + glob.glob(lower):\n",
        "            with open(fn, \"r\", encoding=\"utf-8\") as f:\n",
        "                contents.append(f.read())\n",
        "            target = os.path.split(dn)[-1]\n",
        "            targets.append(target)\n",
        "    df = pd.DataFrame({\n",
        "        \"content\":contents,\n",
        "        \"target\":targets\n",
        "    })\n",
        "    return df\n",
        "train_df = read_data(\"chinese_news_trans\")\n",
        "test_df = read_data(\"chinese_news_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfEq8-Bi_Omn"
      },
      "source": [
        "# Series.replace({\"李白\":0})\n",
        "# unique/value_counts\n",
        "cat = train_df[\"target\"].unique()\n",
        "trans = {w:i for i, w in enumerate(cat)}\n",
        "trans_r = {i:w for i, w in enumerate(cat)}\n",
        "y_train = train_df[\"target\"].replace(trans)\n",
        "y_test = test_df[\"target\"].replace(trans)\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVbwB3FL_iQD"
      },
      "source": [
        "import jieba\n",
        "from urllib.request import urlretrieve\n",
        "url = \"https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big\"\n",
        "urlretrieve(url, \"dict.txt.big\")\n",
        "jieba.set_dictionary(\"dict.txt.big\")\n",
        "# apply(函式名字)\n",
        "def newscut(p):\n",
        "    return \" \".join(jieba.cut(p))\n",
        "x_train = train_df[\"content\"].apply(newscut)\n",
        "x_test = test_df[\"content\"].apply(newscut)\n",
        "x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owIT6KQKAIx8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()\n",
        "x_train_count = vec.fit_transform(x_train)\n",
        "x_test_count = vec.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itzU7B0rAKdd"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB(alpha=0.01)\n",
        "clf.fit(x_train_count, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb02BYlLAbCN"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "pre = clf.predict(x_test_count)\n",
        "accuracy_score(pre, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3k_5wGdA-hO"
      },
      "source": [
        "p = input(\"輸入一首新聞:\")\n",
        "x_predict = vec.transform([newscut(p)])\n",
        "proba = clf.predict_proba(x_predict)[0]\n",
        "for w, p in zip(cat, proba):\n",
        "    print(w, \":\", round(p, 4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}