{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1qR9FP1ztyKoMqlLi3OD5vrwrjlvEbCPk",
      "authorship_tag": "ABX9TyN46/hhy2LzARtHhIAzXqPJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/ml0930/blob/master/transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZNuI-u-9azY"
      },
      "source": [
        "import zipfile\n",
        "f = zipfile.ZipFile(\"drive/My Drive/additional/train.zip\")\n",
        "f.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLew4ODT-bHX"
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "dogs = glob.glob(\"train/dog.*\")\n",
        "cats = glob.glob(\"train/cat.*\")\n",
        "df = pd.DataFrame({\n",
        "    \"path\":dogs + cats,\n",
        "    \"target\":[0] * len(dogs) + [1] * len(cats)\n",
        "})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHEcHVfXCvws"
      },
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "idx = random.randint(0, 24999)\n",
        "load_img(df[\"path\"][idx], target_size=(224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OntCt-TvDe28"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "x, y = np.array(df[\"path\"]), np.array(df[\"target\"])\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16gUVlcFgpp"
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "cnn = vgg16.VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "# freeze一定要在Compile之前\n",
        "for l in cnn.layers:\n",
        "    l.trainable = False\n",
        "mlp = [\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(cnn.layers + mlp)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm9RkWqEI7Wn"
      },
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "       optimizer=Adam(),\n",
        "       metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkcxpY1WJNUG"
      },
      "source": [
        "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n",
        "import numpy as np\n",
        "\n",
        "def getdata(x, y, batch=20):\n",
        "    idx = np.random.randint(0, x.shape[0], size=batch)\n",
        "    orix, batchx, batchy = [], [], y[idx]\n",
        "    for p in x[idx]:\n",
        "        img = load_img(p, target_size=(224, 224))\n",
        "        img_np = np.array(img)\n",
        "        orix.append(img_np)\n",
        "        img_pre = vgg16.preprocess_input(img_np)\n",
        "        batchx.append(img_pre)\n",
        "    return (np.array(orix), np.array(batchx), np.array(batchy))\n",
        "\n",
        "testori, testx, testy = getdata(x_train, y_train, 20)\n",
        "print(testori.shape)\n",
        "print(testx.shape)\n",
        "print(testy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7g9qlbyS2ID"
      },
      "source": [
        "testimg, testx, testy = getdata(x_test, y_test, 200)\n",
        "\n",
        "for i in range(20):\n",
        "    print(\"-\" * 15, i, \"-\" * 15)\n",
        "    trainimg, trainx, trainy = getdata(x_train, y_train, 20)\n",
        "    result = model.train_on_batch(trainx, trainy)\n",
        "    print(\"Train:\", result)\n",
        "    result = model.test_on_batch(testx, testy)\n",
        "    print(\"Validate:\", result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93OD-LzpUf-0"
      },
      "source": [
        "# model.predict(trainx)\n",
        "testimg, testx, testy = getdata(x_test, y_test, 1000)\n",
        "model.evaluate(testx, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3okjPOdcPdP"
      },
      "source": [
        "# subplot(總高度, 總寬度, ith)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "testimg, testx, testy = getdata(x_test, y_test, 1000)\n",
        "pre = model.predict_classes(testx)\n",
        "trans = [\"dog\", \"cat\"]\n",
        "\n",
        "idx = np.nonzero(pre != testy)[0]\n",
        "idx = idx[:200]\n",
        "false_img = testimg[idx]\n",
        "false_label = testy[idx]\n",
        "false_pre = pre[idx]\n",
        "\n",
        "plt.figure(figsize=(14, 14))\n",
        "width = 10\n",
        "height = len(false_img) // width + 1\n",
        "for i in range(len(false_img)):\n",
        "    plt.subplot(height, width, i+1)\n",
        "    title = \"[O]:{}\\n[P]:{}\".format(trans[false_label[i]], trans[false_pre[i]])\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(false_img[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bi1i6X3dobf"
      },
      "source": [
        "\n",
        "# pip install pillow\n",
        "import PIL\n",
        "import requests\n",
        "url = input(\"輸入網址:\")\n",
        "h = {\n",
        "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
        "}\n",
        "response = requests.get(url, stream=True, verify=False, headers=h)\n",
        "img = PIL.Image.open(response.raw).resize((224, 224))\n",
        "img_np = np.array(img)\n",
        "test = vgg16.preprocess_input(img_np.reshape(1, 224, 224, 3))\n",
        "probs = model.predict(test)[0]\n",
        "for i, p in enumerate(probs):\n",
        "    print(trans[i], \"的機率是:\", round(p, 3))\n",
        "ans = model.predict_classes(test)[0]\n",
        "print(\"應該是:\", trans[ans])\n",
        "plt.imshow(img_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}